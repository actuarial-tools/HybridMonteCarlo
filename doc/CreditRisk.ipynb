{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('Python3.7': conda)",
   "display_name": "Python 3.7.6 64-bit ('Python3.7': conda)",
   "metadata": {
    "interpreter": {
     "hash": "af98fb13c0682ca4fe3350401d42f2a404b34a8b53a566210d6d775d501366cd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hybrid Monte Carlo\n",
    "\n",
    "## Credit Risk Analysis\n",
    "\n",
    "In this notebook we give an example of calculating Credit Valuation Adjustments (CVA). First we consider the case where credit risk is assumed independent of other market risk factors. In a second analysis we take into account correlation between credit spreads and market risk factors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # make python find our modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import QuantLib as ql"
   ]
  },
  {
   "source": [
    "We use a Vanilla interest rate swap as example product. The product yields a list of payoffs per observation time.\n",
    "\n",
    "The methodology can easily be adapted to other products. The products just need to implement the *cashFlows()* method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today     = ql.Date(5,ql.October,2020)\n",
    "ql.Settings.instance().evaluationDate = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.products.Swap import Swap\n",
    "discYtsH   = ql.YieldTermStructureHandle(\n",
    "                 ql.FlatForward(today,0.015,ql.Actual365Fixed()))\n",
    "projYtsH   = ql.YieldTermStructureHandle(\n",
    "                 ql.FlatForward(today,0.020,ql.Actual365Fixed()))\n",
    "index      = ql.Euribor6M(projYtsH)\n",
    "startDate  = ql.Date(12,ql.October,2020)\n",
    "endDate    = ql.Date(12,ql.October,2030)\n",
    "calendar   = ql.TARGET()\n",
    "fixedTenor = ql.Period('1y')\n",
    "floatTenor = ql.Period('6m')\n",
    "fixedSchedule = ql.MakeSchedule(startDate,endDate,tenor=fixedTenor,calendar=calendar)\n",
    "floatSchedule = ql.MakeSchedule(startDate,endDate,tenor=floatTenor,calendar=calendar)\n",
    "couponDayCount = ql.Thirty360()\n",
    "notional   = 1.0\n",
    "fixedRate  = 0.02\n",
    "fixedLeg   = ql.FixedRateLeg(fixedSchedule,couponDayCount,[notional],[fixedRate])\n",
    "floatingLeg = ql.IborLeg([notional],floatSchedule,index)\n",
    "#\n",
    "swap = Swap([fixedLeg,floatingLeg],[1.0,-1.0],discYtsH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = swap.cashFlows(0.0)\n",
    "display([str(cf) for cf in cfs])"
   ]
  },
  {
   "source": [
    "## Independent Credit Risk\n",
    "\n",
    "In this subsection we analyse credit risk in the case that credit is independent of other market risk factors. This assumption leads to the classical CVA formula\n",
    "$$\n",
    "  CVA = \\int_0^T \\bar\\lambda(s) e^{-\\int_0^s \\bar\\lambda(u)du} \\cdot\n",
    "        \\mathbb{E}\\left[ e^{-\\int_0^s r(u)du} (1-R) V(s)^+ \\right] ds.\n",
    "$$\n",
    "In this setting, $\\bar\\lambda(s)$ is a hazard rate, $r(s)$ is the risk-free interest rate and $R$ is a recovery rate. The exposure term $V(s)^+$ is the risk-free price of the instrumnt at future time $s$ floored at zero.\n",
    "\n",
    "We can re-write the CVA formula using a discrete set of observation times $0=t_0, t_1, \\ldots, t_n=T$, survival probability $Q(t)=e^{-\\int_0^t \\bar\\lambda(u)du}$ and numeraire $B(t)=e^{-\\int_0^t r(u)du}$. Then\n",
    "$$\n",
    "  CVA = (1-R) \\cdot \\sum_{i=1}^n \\left[ Q(t_{i-1}) - Q(t_{i}) \\right] \\cdot \\frac{1}{2}\n",
    "        \\left[\n",
    "          \\mathbb{E}\\left\\{ \\left[ \\frac{V(t_{i-1})}{B(t_{i-1})} \\right]^+ \\right\\} +\n",
    "          \\mathbb{E}\\left\\{ \\left[ \\frac{V(t_{i})}{B(t_{i})} \\right]^+ \\right\\}\n",
    "        \\right].\n",
    "$$\n",
    "\n",
    "### How does this relate to hybrid modelling?\n",
    "\n",
    "Discounted future payoffs $\\frac{V(t_{i})}{B(t_{i})}$ are simulated within the hybrid Monte Carlo framework:\n",
    "\n",
    "  1.  Define cash flows per observation time.\n",
    "  2.  Derive a time line of cash flows.\n",
    "  3.  Calculate scenario discounted cash flows.\n",
    "\n",
    "For exposure simulation we just need to take the floored values\n",
    "$$\n",
    "  \\left[ \\frac{V(t_{i})}{B(t_{i})} \\right]^+ =\n",
    "  \\max\\left\\{ \\frac{V(t_{i})}{B(t_{i})}, 0 \\right\\}.\n",
    "$$\n",
    "\n",
    "Expectation \\mathbb{E}\\left\\{ \\cdot \\right\\} is approximated as usual via averging the simulated and flored samples.\n",
    "\n",
    "The only remaining piece is calculating the weighted sum using survival probabilities $Q(t_{i})$ ($i=0,\\ldots,n$).\n",
    "\n",
    "### We start with exposure calculation\n",
    "\n",
    "We need to specify the observation times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsTimes = np.linspace(0.0,11.0,41)"
   ]
  },
  {
   "source": [
    "Also we want to specify the number of paths and seed consistently."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPaths = 2**10\n",
    "seed = 314159265359"
   ]
  },
  {
   "source": [
    "Then we set up a model and a simulation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.models.HullWhiteModel import HullWhiteModel\n",
    "from hybmc.simulations.McSimulation import McSimulation\n",
    "ratesModel = HullWhiteModel(discYtsH,0.03,np.array([10.0]),np.array([0.0050]))\n",
    "mcsim = McSimulation(ratesModel,obsTimes,nPaths,seed,True)  # only few paths for demo"
   ]
  },
  {
   "source": [
    "Calculate scenarios, take positive part and show exposure."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_samples = swap.scenarios(obsTimes,mcsim)\n",
    "epeStandard = np.average(np.maximum(V_samples,0.0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=obsTimes,y=epeStandard, labels={'x' : '$t$', 'y' : r'$\\mathbb{E}\\left\\{ \\left[ V(t)/B(t) \\right]^+ \\right\\}$'})\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "### Specify survival probabilities\n",
    "\n",
    "Credit curves are set up as yield term structures. Survival probabilities are calculated as (pseudo) discount factors."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.termstructures.YieldCurve import YieldCurve\n",
    "spreadLevel = 0.05\n",
    "spreadCurve = YieldCurve(spreadLevel)  # use 5% instantanous default probablility\n",
    "Q = np.array([ spreadCurve.discount(t) for t in obsTimes ])\n",
    "#\n",
    "fig = px.line(x=obsTimes,y=Q, labels={'x' : '$t$', 'y' : '$Q(t)$'})\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "### Calculate CVA\n",
    "\n",
    "We assume 40% recovery rate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 0.40\n",
    "CVA = (1-R)/2 * np.sum([ (Q0 - Q1) * (V0 + V1)\n",
    "    for Q0, Q1, V0, V1 in zip(Q[:-1],Q[1:],epeStandard[:-1],epeStandard[1:]) ])\n",
    "display('CVA (Standard): %.4f' % CVA)"
   ]
  },
  {
   "source": [
    "We find that the 10y ATM swap with a 5% counterparty credit spread and 40% recovery rate has a CVA of 37bp."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Correlated Credit Risk\n",
    "\n",
    "In this subsection we analyse the case of correlated credit and market risk. We follow the approach in Brigo/Vrins, Disentangling Wrong-Way Risk, 2016, Sec. 3.3 (https://ssrn.com/abstract=3366804).\n",
    "\n",
    "The method is based on stochastic evolution of an intensity rate $\\lambda(t)$ (Cox process setup). As a first test case we diffuse $\\lambda(t)$ according to a Gaussian model and re-use the Hull White interest rate model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Spread model setup\n",
    "\n",
    "We use the spread curve from independent credit risk simulation. Moreover, we assume 100bp hazard rate volatility and very low mean reversion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean  = 0.0001  # 1bp\n",
    "sigma = 0.0100\n",
    "spreadModel = HullWhiteModel(spreadCurve,mean,np.array([10.0]),np.array([sigma]))"
   ]
  },
  {
   "source": [
    "The Hull White model for spread has the disadvantage that simulated spreads can become negative. To mitigate that property we also set up an alternative model which lets vol go to zero if rates go to zero. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.models.QuasiGaussianModel import QuasiGaussianModel\n",
    "skew = 0.5*sigma/spreadLevel\n",
    "qgModel = QuasiGaussianModel(spreadCurve,1,np.array([10.0]),np.array([[sigma]]),np.array([[skew]]),np.array([[-skew]]),np.array([0.01]),np.array([mean]),np.identity(1))\n",
    "spreadModel = qgModel  #  switch override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.linspace(0.0,0.1,11)\n",
    "X0 = qgModel.initialValues()\n",
    "v = np.array([ qgModel.sigma_f(0.0,X0 + (spread - spreadLevel)) for spread in s ])[:,0]\n",
    "fig = go.Figure()\n",
    "fig.add_trace( go.Scatter(x=s, y=v, mode='lines', name='sigma_f') )\n",
    "fig.update_layout(xaxis_title='$\\lambda$', yaxis_title='volatility')\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "We want to analyse the impact of correlation on exposures and CVA. Thus we setup *three* hybrid credit-rates models:\n",
    "\n",
    "  1.  Negative credit-rates correlation\n",
    "  2.  Zero credit-rates correlation\n",
    "  3.  Positive credit-rates correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.models.CreditModel import CreditModel\n",
    "corrs = [ -0.85, 0.0, 0.85 ]\n",
    "creditModels = []\n",
    "for c in corrs:\n",
    "    corr = np.eye(2)\n",
    "    corr[0,1] = c\n",
    "    corr[1,0] = c\n",
    "    creditModels.append(CreditModel(ratesModel,['CP'],[spreadModel],corr))"
   ]
  },
  {
   "source": [
    "### Model simulation\n",
    "\n",
    "We simulate all the models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcSims = []\n",
    "for model in creditModels:\n",
    "    mcSims.append(McSimulation(model,obsTimes,nPaths,seed,True))  # only few paths for demo"
   ]
  },
  {
   "source": [
    "Since our rates model is the first component model in the credit hyprid model its simulation is not affected by correlation. Thus we only need to simulate it once (and not for each correlation)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_samples = swap.scenarios(obsTimes,mcSims[0])"
   ]
  },
  {
   "source": [
    "However, we do need to simulate the exposure scaling factor and the scaled future swap scenario prices for each correlation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybmc.simulations.CreditPayoffs import zetaScenarios\n",
    "zeta_samples = []\n",
    "V_samples_scaled = []\n",
    "for mcsim in mcSims:\n",
    "    zeta_samples.append(zetaScenarios('CP',obsTimes,mcsim))\n",
    "    V_samples_scaled.append(V_samples*zeta_samples[-1])"
   ]
  },
  {
   "source": [
    "Now, exosure calculation is straight forward and analogous to standard CVA approach."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epeWWR = []\n",
    "for V_s in V_samples_scaled:\n",
    "    epeWWR.append(np.average(np.maximum(V_s,0.0),axis=0))"
   ]
  },
  {
   "source": [
    "Finally, we can compare standard CVA exposures and CVA exposures taking into account WWR and correlation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace( go.Scatter(x=obsTimes, y=epeStandard, mode='lines', name='CVA (Standard)') )\n",
    "for c,epe in zip(corrs,epeWWR):\n",
    "    fig.add_trace( go.Scatter(x=obsTimes, y=epe, mode='lines', name=r'CVA ($\\rho=%.2f$)' % c ) )\n",
    "fig.update_layout(xaxis_title='$t$', yaxis_title='Effective exposure')\n",
    "fig.show()"
   ]
  },
  {
   "source": [
    "Also, we can calculate the corresponding CVA numbers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 0.40\n",
    "CVA = []\n",
    "for c,epe in zip(corrs,epeWWR):\n",
    "    CVA = (1-R)/2 * np.sum([ (Q0 - Q1) * (V0 + V1)\n",
    "        for Q0, Q1, V0, V1 in zip(Q[:-1],Q[1:],epe[:-1],epe[1:]) ])\n",
    "    display('CVA (rho=%.2f): %.4f' % (c,CVA))"
   ]
  },
  {
   "source": [
    "From this analysis we see the followings points:\n",
    "\n",
    "  1.  Non-independent stochastic credit spreads do impact CVA calculation\n",
    "  2.  For a (fixed) receiver swap positive credit-rates correlation leads to smaller CVA (If spreads increase also rates increase, but the receiver swap PV decreases.)\n",
    "  3.  Zero-correlation CVA is not equal to standard CVA assuming independent credit risk!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}